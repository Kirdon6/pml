{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "import tarfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(784, 512),          # First fully connected layer\n",
    "            nn.BatchNorm1d(512),          # Batch normalization\n",
    "            nn.ReLU(),                    # Activation\n",
    "            nn.Dropout(0.3),              # Dropout for regularization\n",
    "\n",
    "            nn.Linear(512, 256),          # Second fully connected layer\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),          # Third fully connected layer\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, num_classes)   # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    def get_activations(self, x):\n",
    "        \"\"\"\n",
    "        Extract features from the penultimate layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 784).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Activations from the penultimate layer.\n",
    "        \"\"\"\n",
    "        for layer in self.network[:-1]:  # Iterate through all layers except the last\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar_gz(file_path, extract_path):\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "    print(f\"Extracted {file_path} to {extract_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_tensors(folder_path):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts to tensor and scales to [0, 1]\n",
    "    ])\n",
    "    image_tensors = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('png', 'jpg', 'jpeg')):  # Check for image files\n",
    "                image_path = os.path.join(root, file)\n",
    "                image = Image.open(image_path).convert('RGB')  # Open and convert to RGB\n",
    "                tensor = transform(image)  # Apply transformations\n",
    "                image_tensors.append(tensor)\n",
    "    return torch.stack(image_tensors)  # Stack into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    \"\"\"\n",
    "    Saves the trained model to the specified path.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained neural network.\n",
    "        path (str): File path to save the model.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_train, dataloader_test, criterion, optimizer, num_epochs, device, save_path=None):\n",
    "\n",
    "    # Metrics to store training and evaluation results\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader_train:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / total\n",
    "        epoch_train_accuracy = correct / total\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader_test:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        epoch_test_loss = running_loss / total\n",
    "        epoch_test_accuracy = correct / total\n",
    "\n",
    "        # Store metrics\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['test_loss'].append(epoch_test_loss)\n",
    "        history['train_accuracy'].append(epoch_train_accuracy)\n",
    "        history['test_accuracy'].append(epoch_test_accuracy)\n",
    "\n",
    "        # Logging\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\"\n",
    "              f\" Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.4f}\"\n",
    "              f\" | Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model after training if a save path is provided\n",
    "    if save_path:\n",
    "        save_model(model, save_path)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_score_from_mnist(images, batch_size=32, splits=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load pre-trained MNIST classifier\n",
    "    model = SimpleNN(10)\n",
    "    model.load_state_dict(torch.load(\"mnist_final.pth\"))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Lambda(lambda x: x + torch.rand_like(x) / 255),  # Dequantize pixel values\n",
    "        transforms.Lambda(lambda x: (x - 0.5) * 2.0),              # Map from [0,1] -> [-1,1]\n",
    "        transforms.Lambda(lambda x: x.mean(dim=0).flatten())       # Convert to grayscale and flatten\n",
    "    ])\n",
    "\n",
    "    # Preprocess images\n",
    "    images = images.to(device)\n",
    "    images = torch.stack([transform(img) for img in images])\n",
    "\n",
    "    # Create batches\n",
    "    dataloader = torch.utils.data.DataLoader(images, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    # Generate predictions for all images\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch_preds = model(batch)  # Get logits\n",
    "            preds.append(F.softmax(batch_preds, dim=1).cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "    # Compute the marginal distribution\n",
    "    py = np.mean(preds, axis=0)\n",
    "\n",
    "    # print(\"Predictions:\", preds[:5])\n",
    "    print(\"Marginal distribution:\", py)\n",
    "    if np.all(py == 0):\n",
    "        raise ValueError(\"Marginal distribution is zero. Check model or input.\")\n",
    "\n",
    "    # Split predictions into chunks for computation\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[i * (len(preds) // splits):(i + 1) * (len(preds) // splits), :]\n",
    "        pyx = np.mean(part, axis=0)\n",
    "        kl_div = pyx * (np.log(pyx + 1e-10) - np.log(py + 1e-10))  # Add epsilon for numerical stability\n",
    "        scores.append(np.sum(kl_div))\n",
    "\n",
    "    # Compute the exponential of the mean KL divergence\n",
    "    return np.exp(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid_from_mnist(real_images, generated_images, batch_size=32):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load pre-trained MNIST classifier\n",
    "    model = SimpleNN(10)\n",
    "    model.load_state_dict(torch.load(\"mnist_final.pth\"))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Lambda(lambda x: x + torch.rand_like(x) / 255),  # Dequantize pixel values\n",
    "            transforms.Lambda(lambda x: (x - 0.5) * 2.0),              # Map from [0,1] -> [-1,1]\n",
    "            transforms.Lambda(lambda x: x.mean(dim=0).flatten())       # Convert 3-channel to grayscale and flatten\n",
    "        ])\n",
    "\n",
    "    def get_activations(images):\n",
    "        \"\"\"Get activations from the penultimate layer of the model.\"\"\"\n",
    "        images = images.to(device)\n",
    "        images = torch.stack([transform(img) for img in images])\n",
    "        dataloader = torch.utils.data.DataLoader(images, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        activations = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                # Get features from the penultimate layer\n",
    "                features = model.get_activations(batch)\n",
    "                activations.append(features.cpu().numpy())\n",
    "\n",
    "        return np.concatenate(activations, axis=0)\n",
    "\n",
    "    # Get activations for real and generated images\n",
    "    real_activations = get_activations(real_images)\n",
    "    generated_activations = get_activations(generated_images)\n",
    "\n",
    "    # Compute mean and covariance for real and generated activations\n",
    "    mu_real = np.mean(real_activations, axis=0)\n",
    "    sigma_real = np.cov(real_activations, rowvar=False)\n",
    "\n",
    "    mu_generated = np.mean(generated_activations, axis=0)\n",
    "    sigma_generated = np.cov(generated_activations, rowvar=False)\n",
    "\n",
    "    # Compute FID\n",
    "    diff = mu_real - mu_generated\n",
    "    covmean, _ = sqrtm(sigma_real @ sigma_generated, disp=False)\n",
    "\n",
    "    # Numerical stability\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    fid = diff @ diff + np.trace(sigma_real + sigma_generated - 2 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x + torch.rand(x.shape)/255),    # Dequantize pixel values\n",
    "    transforms.Lambda(lambda x: (x-0.5)*2.0),                    # Map from [0,1] -> [-1, -1]\n",
    "    transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "# Download and transform train dataset\n",
    "dataloader_train = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data', download=True, train=True, transform=transform),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)\n",
    "\n",
    "# Download and transform test dataset\n",
    "dataloader_test = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data', download=True, train=False, transform=transform),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(num_classes).to(device)\n",
    "\n",
    "#Setting the loss function\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 0.3021, Train Acc: 0.9187 | Test Loss: 0.1063, Test Acc: 0.9667\n",
      "Epoch [2/10] Train Loss: 0.1372, Train Acc: 0.9582 | Test Loss: 0.0799, Test Acc: 0.9748\n",
      "Epoch [3/10] Train Loss: 0.1064, Train Acc: 0.9680 | Test Loss: 0.0726, Test Acc: 0.9762\n",
      "Epoch [4/10] Train Loss: 0.0889, Train Acc: 0.9721 | Test Loss: 0.0670, Test Acc: 0.9785\n",
      "Epoch [5/10] Train Loss: 0.0770, Train Acc: 0.9764 | Test Loss: 0.0625, Test Acc: 0.9806\n",
      "Epoch [6/10] Train Loss: 0.0688, Train Acc: 0.9782 | Test Loss: 0.0636, Test Acc: 0.9813\n",
      "Epoch [7/10] Train Loss: 0.0611, Train Acc: 0.9811 | Test Loss: 0.0628, Test Acc: 0.9804\n",
      "Epoch [8/10] Train Loss: 0.0549, Train Acc: 0.9823 | Test Loss: 0.0540, Test Acc: 0.9842\n",
      "Epoch [9/10] Train Loss: 0.0538, Train Acc: 0.9829 | Test Loss: 0.0564, Test Acc: 0.9831\n",
      "Epoch [10/10] Train Loss: 0.0467, Train Acc: 0.9854 | Test Loss: 0.0566, Test Acc: 0.9848\n",
      "Model saved to mnist_final.pth\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "model_save_path = \"mnist_final.pth\"\n",
    "\n",
    "# Call train_model and save the model\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    dataloader_train=dataloader_train,\n",
    "    dataloader_test=dataloader_test,\n",
    "    criterion=loss_f,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    save_path=model_save_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted epsilon_10k.tar.gz to .\n"
     ]
    }
   ],
   "source": [
    "tar_gz_file = \"epsilon_10k.tar.gz\" \n",
    "extract_to = \".\" \n",
    "extract_tar_gz(tar_gz_file, extract_to)\n",
    "\n",
    "\n",
    "generated_images = load_images_to_tensors(\"epsilon_generated_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toman\\AppData\\Local\\Temp\\ipykernel_80800\\414441351.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"mnist_final.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 7.487852034489004\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_dataloader = torch.utils.data.DataLoader(mnist_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Extract real images\n",
    "real_images, _ = next(iter(mnist_dataloader)) \n",
    "\n",
    "fid_score = calculate_fid_from_mnist(real_images, generated_images, batch_size=32)\n",
    "print(f\"FID Score: {fid_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toman\\AppData\\Local\\Temp\\ipykernel_80800\\751114791.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"mnist_final.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal distribution: [0.07342686 0.10546829 0.10151445 0.10779906 0.12622015 0.11464116\n",
      " 0.06811383 0.12072217 0.0695238  0.11255988]\n",
      "Inception Score: 1.003195881843567\n"
     ]
    }
   ],
   "source": [
    "# Compute Inception Score\n",
    "score = inception_score_from_mnist(generated_images, batch_size=16, splits=10)\n",
    "print(f\"Inception Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted x0_10k.tar.gz to .\n"
     ]
    }
   ],
   "source": [
    "tar_gz_file = \"x0_10k.tar.gz\" \n",
    "extract_to = \".\" \n",
    "extract_tar_gz(tar_gz_file, extract_to)\n",
    "\n",
    "\n",
    "# Load images from the extracted folder\n",
    "generated_images = load_images_to_tensors(\"x0_generated_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toman\\AppData\\Local\\Temp\\ipykernel_80800\\414441351.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"mnist_final.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 6.316408589128564\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts to tensor and scales to [0, 1]\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_dataloader = torch.utils.data.DataLoader(mnist_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Extract real images\n",
    "real_images, _ = next(iter(mnist_dataloader)) \n",
    "\n",
    "fid_score = calculate_fid_from_mnist(real_images, generated_images, batch_size=32)\n",
    "print(f\"FID Score: {fid_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toman\\AppData\\Local\\Temp\\ipykernel_80800\\751114791.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"mnist_final.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal distribution: [0.08378848 0.10766515 0.10215064 0.12205018 0.09766396 0.11008186\n",
      " 0.08145633 0.10755429 0.07944304 0.10813542]\n",
      "Inception Score: 1.0034881830215454\n"
     ]
    }
   ],
   "source": [
    "# Compute Inception Score\n",
    "score = inception_score_from_mnist(generated_images, batch_size=16, splits=10)\n",
    "print(f\"Inception Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
